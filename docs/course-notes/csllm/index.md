---
icon: material/numeric-3-circle
---

# :fontawesome-solid-graduation-cap: Large Language Models (LLMs)
---

## I. Thông tin khóa học

Mô hình ngôn ngữ lớn (Large Language Models - LLMs) đang và sẽ tiếp tục là chủ đề nóng bỏng và nhận được nhiều sự quan tâm của các nhà nghiên cứu và những công ty, tập đoàn lớn trên thế giới về lĩnh vực trí tuệ nhân tạo (Artificial Intelligence - AI). Sau những sự thành công của OpenAI - khi cho ra mắt mô hình ChatGPT vào cuối năm 2022 và mới đây nhất là sự phát triển của DeepSeek, các mô hình LLMs gần như đã chứng tỏ được tiềm năng to lớn trong việc giải quyết các bài toán ngôn ngữ tự nhiên, từ trả lời câu hỏi, tạo nội dung đến hỗ trợ các ứng dụng phức tạp khác.

Khóa học này được thiết kế dựa trên việc ghi chú lại những kiến thức quan trọng và nổi bật theo chủ đề của LLMs giúp bạn nắm vững được những kiến thức cơ bản cũng như các kỹ thuật tiên tiến trong việc triển khai và xây dựng các mô hình ngôn ngữ lớn từ đầu, tương tự như các mô hình nổi bật như GPT của OpenAI.

## II. Bạn sẽ học được những gì?

Không chỉ dừng lại ở việc cung cấp lý thuyết, mà khóa học còn tập trung vào thực hành, giúp bạn có thể tự xây dựng và tối ưu một mô hình GPT-like từ đầu. Khóa học sẽ hỗ trợ bạn:

- Hiểu và nắm bắt được những khái niệm quan trọng của LLMs: Kiến trúc Transformer, Attention Mechanism, Tokenization, v.v.

- Xây dựng mô hình LLMs từ đầu: Dùng Python, PyTorch để thiết kể mô hình tương tự như ChatGPT.

- Huấn luyện và tối ưu hóa: Pre-trainining, Fine-tuning, cải thiện hiệu suất với các kỹ thuật tối ưu hóa.

## III. Yêu cầu

Để có thể dễ dàng theo dõi và nắm bắt được các nội dung trong khóa học này, bạn cần có nền tảng vững chắc ở một số khía cạnh như:

- Kiến thức lập trình: Thành thạo ngôn ngữ Python (biết về Numpy, Pandas, Tensorflow hoặc PyTorch là lợi thế).

- Hiểu về Machine Learning: Nắm vững được các thuật toán học có giám sát (supervised learning) và mạng tích chập (neural network) cơ bản.

- Toán học cơ bản: Hiểu về đại số tuyến tính, xác suất, thống kê và giải tích.

- Kinh nghiệm làm việc với dữ liệu: Biết cách thu thập và tiền xử lý, lằm sạch dữ liệu văn bản.

## IV. Lịch trình bài giảng

| STT | Chủ đề | Mô tả | Trạng thái | Tài liệu |
| :-----: | :---- | :---------- | :----: | :-------: | 
| 01 | Tổng quan về Large Language Model (LLMs) | (--) Khái niệm và ưng dụng của LLMs. <br> (--) Quy trình xây dựng và sử dụng các mô hình LLMs. <br> (--) Giới thiệu về kiến trúc Transformer. <br> (--) Tìm hiểu chi tiết kiến trúc GPT | :material-close: | N/A |
| 02 | Nghiên cứu và làm việc với dữ liệu văn bản | | | |
| 03 | Triển khai cơ chế Attention trong LLMs: Từ Self-Attention đến Multi-Head Attention | (--) Tư duy cách thức hoạt động của self-attention. <br> (--) Các bước triển khai chi tiết self-attention trong Python. <br> (--) Ứng dụng causal masking để kiểm soát thông tin trong các mô hình sinh chuỗi. <br> (--) Kỹ thuật mở rộng từ attention một đầu sang attention nhiều đầu. | :material-close:| {++Pending++} |
